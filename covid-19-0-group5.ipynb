{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# introduction\nLes tests COVID-19 sont actuellement difficiles à trouver - il n'y en a tout simplement pas assez et ils ne peuvent être fabriqués assez rapidement, ce qui provoque la panique.\n\nÉtant donné que les kits de tests COVID-19 sont limités, nous devons nous appuyer sur d'autres mesures de diagnostic.\n\nNous avons pensé à explorer les images radiologiques, car les médecins utilisent fréquemment les rayons X et les tomodensitogrammes pour diagnostiquer les pneumonies, les inflammations pulmonaires, les abcès et/ou les ganglions lymphatiques hypertrophiés.\n\nComme le COVID-19 attaque les cellules épithéliales qui tapissent nos voies respiratoires, nous pouvons utiliser les rayons X pour analyser la santé des poumons d'un patient.\n","metadata":{}},{"cell_type":"markdown","source":"# Chargement des bibliothèques requises","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Data Reading \n\nimport os\nfrom glob import glob\nfrom PIL import Image\n\n# Data Processing \n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport random\nimport albumentations as A\n\n# Data Analysis\n\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data Modeling & Model Evaluation\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import image\nfrom tensorflow.keras import layers, models\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, recall_score, accuracy_score, precision_score, f1_score\n\n# Grad-CAM\n\nimport keras\nimport matplotlib.cm as cm\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:38:18.316934Z","iopub.execute_input":"2022-06-13T00:38:18.317354Z","iopub.status.idle":"2022-06-13T00:38:18.326062Z","shell.execute_reply.started":"2022-06-13T00:38:18.317319Z","shell.execute_reply":"2022-06-13T00:38:18.325107Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Reading The Data**","metadata":{}},{"cell_type":"code","source":"levels = ['Normal/images', 'COVID/images']\npath = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset\"\ndata_dir = os.path.join(path)\n\ndata = []\nfor id, level in enumerate(levels):\n    for file in os.listdir(os.path.join(data_dir, level)):\n        data.append(['{}/{}'.format(level, file), level])\n\ndata = pd.DataFrame(data, columns = ['image_file', 'corona_result'])\n\ndata['path'] = path + '/' + data['image_file']\ndata['corona_result'] = data['corona_result'].map({'Normal/images': 'Negative', 'COVID/images': 'Positive'})\nsamples = 13808\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:38:32.979702Z","iopub.execute_input":"2022-06-13T00:38:32.980645Z","iopub.status.idle":"2022-06-13T00:38:33.442794Z","shell.execute_reply.started":"2022-06-13T00:38:32.980607Z","shell.execute_reply":"2022-06-13T00:38:33.441835Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**verification des données**","metadata":{}},{"cell_type":"code","source":"print('Number of Duplicated Samples: %d'%(data.duplicated().sum()))\nprint('Number of Total Samples: %d'%(data.isnull().value_counts()))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:38:45.168006Z","iopub.execute_input":"2022-06-13T00:38:45.168428Z","iopub.status.idle":"2022-06-13T00:38:45.196362Z","shell.execute_reply.started":"2022-06-13T00:38:45.168396Z","shell.execute_reply":"2022-06-13T00:38:45.195384Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**\n**1. Count Plot**","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['corona_result'] = ['Positive', 'Negative']\ndf['counts'] = [len(data[data['corona_result'] == 'Positive']), len(data[data['corona_result'] == 'Negative'])]\ndf = df.sort_values(by = ['counts'], ascending = False)\n\nfig = px.bar(df, x = 'corona_result', y = 'counts', \n             color = \"corona_result\", text_auto='', width = 600, \n             color_discrete_sequence = [\"orange\", \"purple\"],\n             template = 'plotly_dark')\n\nfig.update_xaxes(showgrid = False)\nfig.update_yaxes(showgrid = False)\nfig.update_traces(textfont_size = 12, textangle = 0, textposition = \"outside\", cliponaxis = False)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:38:59.573222Z","iopub.execute_input":"2022-06-13T00:38:59.573601Z","iopub.status.idle":"2022-06-13T00:39:00.854568Z","shell.execute_reply.started":"2022-06-13T00:38:59.573572Z","shell.execute_reply":"2022-06-13T00:39:00.853642Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**2. Image Samples**","metadata":{}},{"cell_type":"markdown","source":"**2.1.Transformez les images en tableaux et créez une liste de classes.**\n\n redimensionnement des images  à 75x75.","metadata":{}},{"cell_type":"code","source":"data['image'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((75,75))))\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:39:40.758474Z","iopub.execute_input":"2022-06-13T00:39:40.758900Z","iopub.status.idle":"2022-06-13T00:41:12.639537Z","shell.execute_reply.started":"2022-06-13T00:39:40.758866Z","shell.execute_reply":"2022-06-13T00:41:12.638407Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"n_samples = 5\n\nfig, m_axs = plt.subplots(2, n_samples, figsize = (6*n_samples, 3*4))\n\nfor n_axs, (type_name, type_rows) in zip(m_axs, data.sort_values(['corona_result']).groupby('corona_result')):\n    n_axs[1].set_title(type_name, fontsize = 15)\n    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state = 0).iterrows()):       \n        picture = c_row['path']\n        image = cv2.imread(picture)\n        c_ax.imshow(image)\n        c_ax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:42:42.135660Z","iopub.execute_input":"2022-06-13T00:42:42.136242Z","iopub.status.idle":"2022-06-13T00:42:43.158062Z","shell.execute_reply.started":"2022-06-13T00:42:42.136198Z","shell.execute_reply":"2022-06-13T00:42:43.157261Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nimage = cv2.imread(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images/COVID-1002.png\")\nplt.imshow(image)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:42:51.495867Z","iopub.execute_input":"2022-06-13T00:42:51.496300Z","iopub.status.idle":"2022-06-13T00:42:51.628245Z","shell.execute_reply.started":"2022-06-13T00:42:51.496266Z","shell.execute_reply":"2022-06-13T00:42:51.626894Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print('Image Shape: {}'.format(image.shape))\nprint('Image Height: {}'.format(image.shape[0]))\nprint('Image Width: {}'.format(image.shape[1]))\nprint('Image Dimension: {}'.format(image.ndim))\nprint('Image Size: {}kb'.format(image.size//1024))\nprint('Image Data Type: {}'.format(image.dtype))\nprint('Maximum RGB value of the image: {}'.format(image.max()))\nprint('Minimum RGB value of the image: {}'.format(image.min()))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:42:59.487882Z","iopub.execute_input":"2022-06-13T00:42:59.488308Z","iopub.status.idle":"2022-06-13T00:42:59.496449Z","shell.execute_reply.started":"2022-06-13T00:42:59.488275Z","shell.execute_reply":"2022-06-13T00:42:59.495492Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"****Nous observons que l'image possède 3 canaux, donc qu'elle est en échelle RVB même s'il s'agit d'images radiologiques.","metadata":{}},{"cell_type":"markdown","source":"**4. Canal B**","metadata":{}},{"cell_type":"code","source":"plt.title('B channel', fontsize = 14)\nplt.imshow(image[ : , : , 0])\nplt.axis('off');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:43:07.422722Z","iopub.execute_input":"2022-06-13T00:43:07.423138Z","iopub.status.idle":"2022-06-13T00:43:07.572317Z","shell.execute_reply.started":"2022-06-13T00:43:07.423105Z","shell.execute_reply":"2022-06-13T00:43:07.571399Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**5. La méthode de Ben Graham**","metadata":{}},{"cell_type":"markdown","source":"Tout d'abord, nous convertissons les images en niveaux de gris, puis nous leur appliquons un flou gaussien.","metadata":{}},{"cell_type":"code","source":"all_covid = []\nall_normal = []\n\nall_normal.extend(glob(os.path.join(path, \"Normal/images/*.png\")))\nall_covid.extend(glob(os.path.join(path, \"COVID/images/*.png\")))\n\nrandom.shuffle(all_normal)\nrandom.shuffle(all_covid)\n\nimages = all_normal[:50] + all_covid[:50]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:43:17.829016Z","iopub.execute_input":"2022-06-13T00:43:17.829454Z","iopub.status.idle":"2022-06-13T00:43:17.910507Z","shell.execute_reply.started":"2022-06-13T00:43:17.829420Z","shell.execute_reply":"2022-06-13T00:43:17.909569Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (18, 7))\nfig.suptitle(\"Ben Grahamns Method of Analysis\", fontsize = 15)\ncolumns = 4; rows = 2\n\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), 512/10), -4, 128)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(False)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:43:27.577660Z","iopub.execute_input":"2022-06-13T00:43:27.578425Z","iopub.status.idle":"2022-06-13T00:43:32.256679Z","shell.execute_reply.started":"2022-06-13T00:43:27.578386Z","shell.execute_reply":"2022-06-13T00:43:32.255694Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**6. Visualisation des albuminations**","metadata":{}},{"cell_type":"code","source":"def plot_multiple_img(img_matrix_list, title_list, ncols, main_title = \"\"):\n    \n    fig, myaxes = plt.subplots(figsize = (15, 8), nrows = 2, ncols = ncols, squeeze = False)\n    fig.suptitle(main_title, fontsize = 18)\n    fig.subplots_adjust(wspace = 0.3)\n    fig.subplots_adjust(hspace = 0.3)\n    \n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i // ncols][i % ncols].imshow(img)\n        myaxes[i // ncols][i % ncols].set_title(title, fontsize = 15)\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:43:38.578011Z","iopub.execute_input":"2022-06-13T00:43:38.578475Z","iopub.status.idle":"2022-06-13T00:43:38.585844Z","shell.execute_reply.started":"2022-06-13T00:43:38.578438Z","shell.execute_reply":"2022-06-13T00:43:38.585028Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"chosen_image = cv2.imread(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images/COVID-1.png\")\n\nalbumentation_list = [A.RandomFog(p = 1), A.RandomBrightness(p = 1),\n                      A.RandomCrop(p = 1,height = 199, width = 199), A.Rotate(p = 1, limit = 90),\n                      A.RGBShift(p = 1), A.VerticalFlip(p = 1), A.RandomContrast(limit = 0.5, p = 1)]\n\nimg_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\n\nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\", \"RandomFog\", \"RandomBrightness\", \"RandomCrop\", \"Rotate\", \"RGBShift\", \"VerticalFlip\", \"RandomContrast\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 4, main_title = \"Different Types of Augmentations\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:43:50.378597Z","iopub.execute_input":"2022-06-13T00:43:50.379070Z","iopub.status.idle":"2022-06-13T00:43:51.360818Z","shell.execute_reply.started":"2022-06-13T00:43:50.379034Z","shell.execute_reply":"2022-06-13T00:43:51.360023Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**7. Image Value Distribution**","metadata":{}},{"cell_type":"code","source":"mean_val = []\nstd_dev_val = []\nmax_val = []\nmin_val = []\n\nfor i in range(0, samples):\n    mean_val.append(data['image'][i].mean())\n    std_dev_val.append(np.std(data['image'][i]))\n    max_val.append(data['image'][i].max())\n    min_val.append(data['image'][i].min())\n\nimageEDA = data.loc[:,['image','corona_result','path']]\nimageEDA['mean'] = mean_val\nimageEDA['stedev'] = std_dev_val\nimageEDA['max'] = max_val\nimageEDA['min'] = min_val\n\nimageEDA['subt_mean'] = imageEDA['mean'].mean() - imageEDA['mean']","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:44:26.722870Z","iopub.execute_input":"2022-06-13T00:44:26.723260Z","iopub.status.idle":"2022-06-13T00:44:28.655121Z","shell.execute_reply.started":"2022-06-13T00:44:26.723229Z","shell.execute_reply":"2022-06-13T00:44:28.654407Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"ax1 = sns.displot(data = imageEDA, x = 'mean', kind=\"kde\", hue = 'corona_result');\nplt.title('Images Colour Mean Value Distribution by Class\\n', fontsize = 12);\n\nax2 = sns.displot(data = imageEDA, x = 'max', kind=\"kde\", hue = 'corona_result');\nplt.title('\\nImages Colour Max Value Distribution by Class\\n', fontsize = 12);\n\nax3 = sns.displot(data = imageEDA, x = 'min', kind=\"kde\", hue = 'corona_result');\nplt.title('\\nImages Colour Min Value Distribution by Class\\n', fontsize = 12);","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:44:36.567856Z","iopub.execute_input":"2022-06-13T00:44:36.568259Z","iopub.status.idle":"2022-06-13T00:44:38.103289Z","shell.execute_reply.started":"2022-06-13T00:44:36.568227Z","shell.execute_reply":"2022-06-13T00:44:38.102297Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Le graphique de la moyenne par rapport à la densité donne des indications sur les pixels :**\n\n1. La valeur maximale du pixel pour les cas Covid Négatif est supérieure à 0,014 et inférieure à 0,016.\n1. La valeur maximale des pixels dans les cas de Covid positif est supérieure à 0,004 et inférieure à 0,006.\n\n**Le graphique Max vs Densité donne des indications sur les pixels :**\n\n1. La valeur maximale des pixels pour les cas de Covid Negative est supérieure à 0,035 et inférieure à 0,040.\n1. La valeur maximale du pixel pour les cas de Covid positif est de 0,005.\n\n**Le graphique Min vs Densité donne des indications sur les pixels :**\n\n1. La valeur maximale du pixel pour les cas Covid Négatif est supérieure à 0.4.\n1. La valeur maximale des pixels pour les cas de Covid Positif est supérieure à 0,0 et inférieure à 0,1.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 8))\nsns.set(style = \"ticks\", font_scale = 1)\nax = sns.scatterplot(data = imageEDA, x = \"mean\", y = imageEDA['stedev'], hue = 'corona_result', alpha = 0.8);\nsns.despine(top = True, right = True, left = False, bottom = False)\nplt.xticks(rotation = 0, fontsize = 12)\nax.set_xlabel('\\nImage Channel Colour Mean', fontsize = 14)\nax.set_ylabel('Image Channel Colour Standard Deviation', fontsize = 14)\nplt.title('Mean and Standard Deviation of Image Samples', fontsize = 16);","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:44:45.568129Z","iopub.execute_input":"2022-06-13T00:44:45.568553Z","iopub.status.idle":"2022-06-13T00:44:46.309644Z","shell.execute_reply.started":"2022-06-13T00:44:45.568512Z","shell.execute_reply":"2022-06-13T00:44:46.308682Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Nous observons qu'il y a 2 clusters formés, un pour Covid Positif, un pour Covid Négatif et les deux ont plusieurs chevauchements. Couleur de chevauchement Plage moyenne : (100 - 175)\n\nNous observons que les pixels ayant un écart-type inférieur à 30 sont tous des images Covid Positives (couleur orange).","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 8));\ng = sns.FacetGrid(imageEDA, col = \"corona_result\", height = 5);\ng.map_dataframe(sns.scatterplot, x = 'mean', y = 'stedev');\ng.set_titles(col_template = \"{col_name}\", row_template= \"{row_name}\", size = 12);\ng.fig.subplots_adjust(top = .7);\ng.fig.suptitle('Mean and Standard Deviation of Image Samples', fontsize = 15);\naxes = g.axes.flatten();\naxes[0].set_ylabel('Standard Deviation');\nfor ax in axes:\n    ax.set_xlabel('\\nMean');\ng.fig.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:44:53.099310Z","iopub.execute_input":"2022-06-13T00:44:53.099701Z","iopub.status.idle":"2022-06-13T00:44:53.625064Z","shell.execute_reply.started":"2022-06-13T00:44:53.099672Z","shell.execute_reply":"2022-06-13T00:44:53.624089Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"En comparant les deux diagrammes de dispersion, nous observons que les échantillons de Postivie présentent des valeurs aberrantes (points de pixels).\n\n**8. Perception de soi**\n\n\n**Modélisation des données**\nTrain Test Split","metadata":{}},{"cell_type":"code","source":"all_data = []\n\n# Storing images and their labels into a list for further Train Test split\n\nfor i in range(len(data)):\n    image = cv2.imread(data['path'][i])\n    image = cv2.resize(image, (70, 70)) / 255.0\n    label = 1 if data['corona_result'][i] == \"Positive\" else 0\n    all_data.append([image, label])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:45:06.688320Z","iopub.execute_input":"2022-06-13T00:45:06.688726Z","iopub.status.idle":"2022-06-13T00:45:44.172259Z","shell.execute_reply.started":"2022-06-13T00:45:06.688694Z","shell.execute_reply":"2022-06-13T00:45:44.171412Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"x = []\ny = []\n\nfor image, label in all_data:\n    x.append(image)\n    y.append(label)\n\n# Converting to Numpy Array    \nx = np.array(x)\ny = np.array(y)\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)\n\nprint(x_train.shape, x_test.shape, x_val.shape, y_train.shape, y_test.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:46:12.118702Z","iopub.execute_input":"2022-06-13T00:46:12.119187Z","iopub.status.idle":"2022-06-13T00:46:13.921299Z","shell.execute_reply.started":"2022-06-13T00:46:12.119153Z","shell.execute_reply":"2022-06-13T00:46:13.920282Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model","metadata":{}},{"cell_type":"code","source":"cnn_model = models.Sequential()\ncnn_model.add(layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (70, 70, 3)))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Dropout(0.3))\n\ncnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\ncnn_model.add(layers.MaxPooling2D((2, 2)))\ncnn_model.add(layers.Dropout(0.5))\n\ncnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\ncnn_model.add(layers.Flatten())\ncnn_model.add(layers.Dense(units = 16, activation = 'relu'))\ncnn_model.add(layers.Dropout(0.2))\n\ncnn_model.add(layers.Dense(units = 2))\n\ncnn_model.compile(optimizer = 'adam', \n           loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n           metrics = ['accuracy'])\n\ncnn_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:46:28.465645Z","iopub.execute_input":"2022-06-13T00:46:28.466059Z","iopub.status.idle":"2022-06-13T00:46:28.661860Z","shell.execute_reply.started":"2022-06-13T00:46:28.466025Z","shell.execute_reply":"2022-06-13T00:46:28.660864Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n\n#tf.random.set_seed(42)\nhistory = cnn_model.fit(x_train, y_train, \n                        epochs = 30, batch_size = 256,  \n                        validation_data = (x_val, y_val), \n                        callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T00:46:37.228095Z","iopub.execute_input":"2022-06-13T00:46:37.228587Z","iopub.status.idle":"2022-06-13T01:25:36.000748Z","shell.execute_reply.started":"2022-06-13T00:46:37.228554Z","shell.execute_reply":"2022-06-13T01:25:35.999703Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"yp_train = cnn_model.predict(x_train)\nyp_train = np.argmax(yp_train, axis = 1)\n\nyp_val = cnn_model.predict(x_val)\nyp_val = np.argmax(yp_val, axis = 1)\n\nyp_test = cnn_model.predict(x_test)\nyp_test = np.argmax(yp_test, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:26:31.673000Z","iopub.execute_input":"2022-06-13T01:26:31.673404Z","iopub.status.idle":"2022-06-13T01:27:01.108674Z","shell.execute_reply.started":"2022-06-13T01:26:31.673373Z","shell.execute_reply":"2022-06-13T01:27:01.107504Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"def evaluation_parametrics(name, y_train, yp_train, y_val, yp_val, y_test, yp_test):\n    \n    print(\"\\n-----------------------------{}-----------------------------\\n\".format(name))\n    \n    cm_train = confusion_matrix(y_train, yp_train)\n    t1 = ConfusionMatrixDisplay(cm_train)\n    s1 = round((cm_train[0,0]/(cm_train[0,0] + cm_train[0,1])),4)\n    \n    print(\"Classification Report for Train Data\\n\")\n    print(classification_report(y_train, yp_train)) \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Train Data: \", round(recall_score(y_train, yp_train),4))\n    print(\"Specificity on Train Data: \", s1)\n    print(\"Accuracy on Train Data: \", round(accuracy_score(y_train, yp_train),4))\n    print(\"Precision on Train Data: \", round(precision_score(y_train, yp_train),4))\n    print(\"F1 Score on Train Data: \", round(f1_score(y_train, yp_train),4))\n    print(\"--------------------------------------------------------------------------\")\n       \n    cm_val = confusion_matrix(y_val, yp_val)\n    t2 = ConfusionMatrixDisplay(cm_val)\n    s2 = round((cm_val[0,0]/(cm_val[0,0] + cm_val[0,1])),4)\n    \n    print(\"\\nClassification Report for Validation Data\\n\")\n    print(classification_report(y_val, yp_val))   \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Val Data: \", round(recall_score(y_val, yp_val),4))\n    print(\"Specificity on Val Data: \", s2)\n    print(\"Accuracy on Val Data: \", round(accuracy_score(y_val, yp_val),4))\n    print(\"Precision on Val Data: \", round(precision_score(y_val, yp_val),4))\n    print(\"F1 Score on Val Data: \", round(f1_score(y_val, yp_val),4))\n    print(\"--------------------------------------------------------------------------\")\n\n    cm_test = confusion_matrix(y_test, yp_test)\n    t3 = ConfusionMatrixDisplay(cm_test)\n    s3 = round((cm_test[0,0]/(cm_test[0,0] + cm_test[0,1])),4)\n    \n    print(\"\\nClassification Report for Test Data\\n\")\n    print(classification_report(y_test, yp_test))   \n    print(\"--------------------------------------------------------------------------\")\n    print(\"Recall on Test Data: \", round(recall_score(y_test, yp_test), 4))\n    print(\"Specificity on Test Data: \", s3)\n    print(\"Accuracy on Test Data: \", round(accuracy_score(y_test, yp_test), 4))\n    print(\"Precision on Test Data: \", round(precision_score(y_test, yp_test), 4))\n    print(\"F1 Score Test Data: \", round(f1_score(y_test, yp_test), 4))\n    print(\"--------------------------------------------------------------------------\")\n    \n    t1.plot()\n    t2.plot()   \n    t3.plot()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:27:07.883928Z","iopub.execute_input":"2022-06-13T01:27:07.884335Z","iopub.status.idle":"2022-06-13T01:27:07.902250Z","shell.execute_reply.started":"2022-06-13T01:27:07.884304Z","shell.execute_reply":"2022-06-13T01:27:07.901551Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"evaluation_parametrics(\"Convolution Neural Network\", y_train, yp_train, y_val, yp_val, y_test, yp_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:27:15.529615Z","iopub.execute_input":"2022-06-13T01:27:15.530048Z","iopub.status.idle":"2022-06-13T01:27:16.229178Z","shell.execute_reply.started":"2022-06-13T01:27:15.530013Z","shell.execute_reply":"2022-06-13T01:27:16.228097Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# list all data in history\n\nprint(history.history.keys())","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:27:36.553477Z","iopub.execute_input":"2022-06-13T01:27:36.553902Z","iopub.status.idle":"2022-06-13T01:27:36.559442Z","shell.execute_reply.started":"2022-06-13T01:27:36.553868Z","shell.execute_reply":"2022-06-13T01:27:36.558510Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Summarize History for Accuracy\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc = 'lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:29:14.274578Z","iopub.execute_input":"2022-06-13T01:29:14.275009Z","iopub.status.idle":"2022-06-13T01:29:14.476756Z","shell.execute_reply.started":"2022-06-13T01:29:14.274968Z","shell.execute_reply":"2022-06-13T01:29:14.475660Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc = 'upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:27:45.098759Z","iopub.execute_input":"2022-06-13T01:27:45.099192Z","iopub.status.idle":"2022-06-13T01:27:45.295776Z","shell.execute_reply.started":"2022-06-13T01:27:45.099158Z","shell.execute_reply":"2022-06-13T01:27:45.294854Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Accuracy Loss Graph\n\npd.DataFrame(history.history).plot()\nplt.title('Model Accuracy/Loss')\nplt.ylabel('Accuracy/Loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:27:56.319663Z","iopub.execute_input":"2022-06-13T01:27:56.320131Z","iopub.status.idle":"2022-06-13T01:27:56.554529Z","shell.execute_reply.started":"2022-06-13T01:27:56.320096Z","shell.execute_reply":"2022-06-13T01:27:56.553614Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**Création d'un Viz superposé**","metadata":{}},{"cell_type":"markdown","source":"**Positive-1 Sample Insight :** Dans son image Grad-CAM, sur la partie médiane droite, on peut voir la portion en surbrillance de couleur bleue qui correspond à l'opacité et qui appartient à la catégorie COVID - Positive.\n\n**Exemple positif-2 :** Dans son image Grad-CAM, dans la partie inférieure gauche, on peut voir la partie en surbrillance de couleur bleu-vert qui est la consolidation et pas de Tree-Bud, ce qui fait qu'il appartient à la catégorie COVID - Positive.\n\n**Echantillon Negative-1 :** Sur l'image Grad-CAM, on peut voir la partie en surbrillance de couleur bleue située entre le cœur et le diaphragme. Aucune opacité n'a été détectée, ce qui correspond à la catégorie COVID - Negative.\n\n**Negative-2 Sample Insight :** Dans l'image Grad-CAM, on peut voir la portion de couleur bleue qui met en évidence la Trachée. Aucune autre opacité n'a été détectée, ce qui explique son appartenance à la catégorie COVID - Negative.\n","metadata":{}},{"cell_type":"markdown","source":"# Vérification des prédictions pour les échantillons d'images ci-dessus","metadata":{}},{"cell_type":"code","source":"# \n\nfor i in img_path:Checking predictions for the above sample images\n    z_img = cv2.imread(i)\n    z_img = cv2.resize(z_img, (70, 70)) / 255.0\n    z_img = z_img.reshape(1, z_img.shape[0], z_img.shape[1], z_img.shape[2])\n    \n    z = cnn_model.predict(z_img)\n    z = np.argmax(z, axis = 1)\n    print(\"Image\", img_path.index(i) + 1, \":\", z)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T02:12:36.594723Z","iopub.execute_input":"2022-06-13T02:12:36.595156Z","iopub.status.idle":"2022-06-13T02:12:36.827367Z","shell.execute_reply.started":"2022-06-13T02:12:36.595112Z","shell.execute_reply":"2022-06-13T02:12:36.826376Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"cnn_model.save('cnn_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T01:49:12.207983Z","iopub.execute_input":"2022-06-13T01:49:12.208380Z","iopub.status.idle":"2022-06-13T01:49:12.248409Z","shell.execute_reply.started":"2022-06-13T01:49:12.208347Z","shell.execute_reply":"2022-06-13T01:49:12.247414Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n1. Analyse exploratoire des données d'image sur les images Covid et normales en utilisant diverses techniques.\n\n1. Application du modèle de réseau neuronal à convolution et obtention d'une bonne précision et d'une bonne perte, tout en évitant le surajustement.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Réferences\nhttps://www.kaggle.com/code/sana306/detection-of-covid-positive-cases-using-dl/notebook","metadata":{}}]}